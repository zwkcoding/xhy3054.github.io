---
layout: post
title: 基于词袋模型的图像匹配 
date: 2019-04-19 10:07:24.000000000 +09:00
img:  sword/sword7.jpg # Add image post (optional)
tag: [图像处理]
---

看orb-slam的时候发现它在回环检测的时候使用了基于视觉词袋的图像匹配，现在有了一点心得，虽然还有些东西没有完全吃透，但最近比较忙，可能不会有时间在这里死磕，所以先将目前所得写下来，省的忘了。以后有时间完全吃透了会继续完善这篇文章。

# Bag-of-words模型简介
词袋模型在信息检索领域使用的比较多，以前上课时就听老师讲过，是很常见的算法。在信息检索中，Bow忽略一个文档中单词出现的顺序、语法、句式等信息，仅仅将文档看成一个集合，集合的元素是单词。如下两个文档：

1. Bob likes to play basketball, Jim likes too.
2. Bob also likes to play football games.

基于上面两个文档，我们可以为其创建一个**词典**:

    {1:"Bob", 2:"likes", 3:"to", 4:"play", 5:"basketball", 6:"also", 7:"football", 8:"games", 9:"Jim", 10:"too"}

依据上面这个词典，我们可以将例子中的两个文档表示成如下两个**向量**:

1. [1, 2, 1, 1, 1, 0, 0, 0, 1, 1]
2. [1, 1, 1, 1, 0, 1, 1, 1, 0, 0]

向量中每个元素表示词典中相关元素在文档中出现的次数。我们可以通过度量文档向量之间的相似程度来衡量文档之间的相似程度。

# orbslam中的应用
在局部特征点的视觉词典中，每一个单词是具有某一类特征的特征点。在orbslam中使用了DBoW2这个库，这个库的作者提供的ORB特征的词典是其在很大的图像数据集上离线训练好的，我们可以假设任何一个orb特征点都可以在这个词典里找到自己所属的单词类。

> 在Vocabulary文件夹下的`ORBvoc.txt`文件就是词典，大概有150M大小

## 构造离线词典
在构造离线词典时，使用了分层K-means树的存储结构，这个结构在快速寻找k近邻里面也会经常用到。大概流程如下

1. 从训练图像中提取大量特征

2. 将抽取的特征描述子使用`k-means`聚类算法进行聚类(使用汉明距离)，将整个特征空间划分为k类

3. 在上一步中划分的每个子空间中，继续利用`k-means`聚类算法进行聚类

4. 重复上述第三步，将描述子空间通过一个k叉树进行划分

## 图像的匹配
1. 对每一副图片，提取orb特征点

2. 对每个orb特征点从词典树的根节点往下遍历，每次进入汉明距离最小的节点，直到抵达叶节点。此时得到这个特征点所属的单词

3. 通过上述步骤得到输入图片的向量表示，可以使用这个向量进行图片的搜索、匹配等。


# 参考文献
[1] https://www.cnblogs.com/zjiaxing/p/5548265.html
[2] https://blog.csdn.net/hzwwpgmwy/article/details/83477990
[3] Mur-Artal R, Montiel J M M, Tardos J D. ORB-SLAM: a versatile and accurate monocular SLAM system[J]. IEEE transactions on robotics, 2015, 31(5): 1147-1163.


