I"	<h2 id="inception-由来">Inception 由来</h2>
<p>2014年，<strong>GoogLeNet</strong>在ImageNet竞赛上击败<strong>VGGNet</strong>一举夺魁。其中，GooLeNet首次提出Iception结构，早期的Iception-v1结构借鉴了NIN（Network in Network）的设计思想，对网络的传统卷积层进行了修改，并一直改进到v4,改进过程中主要是针对以下限制神经网络性能的主要问题：</p>
<ol>
  <li>参数空间大，容易过拟合，且训练数据集有限;</li>
  <li>网络结构复杂，计算资源不足，导致难以应用;</li>
  <li>深层次网络结构容易出现梯度弥散，模型性能下降。</li>
</ol>

<h2 id="inception">Inception</h2>
<p>首先，一开始提出Inception为的是<strong>增加网络的适应能力</strong>。应用到图像领域，层级越高，所对应的原始图像的视野就越大，同样大小的卷积核往往难以捕捉到不同的特征。因而层级越高，卷积核的数目也应该增加，即使用不同尺寸的卷积核共同进行特征提取。
<img src="/assets/img/Inception/naive.png" alt="naive" /></p>

<p>如上图所示，分别使用了<strong>1×1、3×3、5×5</strong>的卷积核，并且加入了<strong>3×3</strong>的<strong>max pooling</strong>。但是这样的结构存在着明显的问题：每一层的Inception结构上的参数量为所有分支上参数量的总和，多层Inception最终会导致模型的参数数量庞大，对计算资源需求巨大。</p>

<h3 id="inception_v1">Inception_v1</h3>
<p>为了减少计算量，在不损失模型特征表示能力的前提下，在v1中又提出了使用<strong>1×1</strong>卷积核进行降维，达到降低模型复杂度的目的：
<img src="/assets/img/Inception/v1.png" alt="v1" /></p>

<p>如图，在<strong>3×3、5×5</strong>的卷积核之前，使用<strong>1×1</strong>卷积核进行降维，大大减少了参数量。</p>

<ul>
  <li>1×1卷积核降维原理：比如100×100×3的图片，直接3×3卷积核卷积共进行<code class="highlighter-rouge">a=100×100×3×3×3</code>此运算。而使用1×1卷积核首先进行<code class="highlighter-rouge">b=100×100×3</code>次运算，然后再与3×3卷积核卷积进行<code class="highlighter-rouge">c=100×100×3×3</code>次运算,明显<code class="highlighter-rouge">a&gt;b+c</code>（计算运算量时只考虑了乘法数量）。</li>
</ul>

<h3 id="inception_v2">Inception_v2</h3>
<h3 id="inception_v3">Inception_v3</h3>
<h3 id="inception_v4">Inception_v4</h3>
:ET